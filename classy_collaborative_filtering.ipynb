{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyNVtIK+2mc7O6c7FXnGGE1Q",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cchummer/ml-dl-scratch/blob/main/classy_collaborative_filtering.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Collaborative Filtering from Scratch\n",
        "\n",
        "These models were developed around the movielens dataset, with the main goal of learning to predict specific users' ratings of specific titles. However, collaborative filtering has applications in many scenarios where a system might benefit from correctly predicting a user's preferences or tastes. Two variations of probabalistic matrix factorization (PMF) based models are given, and two neural net based."
      ],
      "metadata": {
        "id": "tX0Xq_8OAGu4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "lO9OjVGfaVpl"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Datasets + Dataloaders\n",
        "\n",
        "We have four variations of colaborative filtering, using two custom dataset structures. The two PMF models are quite similar, with one simply incorporating an extra feature (on top of the assumed item and users). Same goes for the two NN models. During development, this extra feature was movie genre data. This could easily be modified or extended to incorporate more features as needed."
      ],
      "metadata": {
        "id": "toDJC9Vh-txv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Utilizing pytorch Dataset + DataLoader functionality for easy batch size control + ID mapping\n",
        "class collabSimpleDataset(Dataset):\n",
        "  def __init__(self, df, user_col, item_col, score_col):\n",
        "\n",
        "    # Create mappings of user and item ids to 0-based indices so they will play nicely with embedding lookups. Also allows for use of non-numeric columns (movie title, etc)\n",
        "    self.user_col = user_col\n",
        "    self.item_col = item_col\n",
        "    self.score_col = score_col\n",
        "\n",
        "    self.data = df\n",
        "    self.user_mapping = {user_id: i for i, user_id in enumerate(self.data[self.user_col].unique())}\n",
        "    self.item_mapping = {item_id: i for i, item_id in enumerate(self.data[self.item_col].unique())}\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.data)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    user_id = self.data.iloc[idx][self.user_col]\n",
        "    item_id = self.data.iloc[idx][self.item_col]\n",
        "    rating = self.data.iloc[idx][self.score_col]\n",
        "\n",
        "    # Return our index values rather than the raw ID's (which are potentially non-numeric)\n",
        "    # This has the effect of indices rather than ID's being returned to forward() in the model below\n",
        "    user_idx = self.user_mapping[user_id]\n",
        "    item_idx = self.item_mapping[item_id]\n",
        "\n",
        "    #user_idx_tensor = torch.tensor(user_idx, dtype=torch.long)\n",
        "    #item_idx_tensor = torch.tensor(item_idx, dtype=torch.long)\n",
        "    #ratings_tensor = torch.tensor(rating, dtype=torch.float32)\n",
        "\n",
        "    #return [user_idx, item_idx, ratings_tensor]\n",
        "    return torch.tensor([user_idx, item_idx, rating], dtype=torch.float32)"
      ],
      "metadata": {
        "id": "ZfE_TUSL-G_u"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a new dataset which will also hold genre data\n",
        "class collabExtendedDataset(Dataset):\n",
        "  def __init__(self, df, user_col, item_col, genre_col, score_col):\n",
        "\n",
        "    self.user_col = user_col\n",
        "    self.item_col = item_col\n",
        "    self.genre_col = genre_col\n",
        "    self.score_col = score_col\n",
        "\n",
        "    self.data = df\n",
        "    self.user_mapping = {user_id: i for i, user_id in enumerate(self.data[self.user_col].unique())}\n",
        "    self.item_mapping = {item_id: i for i, item_id in enumerate(self.data[self.item_col].unique())}\n",
        "\n",
        "    # Create our mapping of unique genres\n",
        "    self.genres_list = self._get_unique_genres()\n",
        "    self.genre_mapping = {genre: i for i, genre in enumerate(self.genres_list)}\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.data)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    user_id = self.data.iloc[idx][self.user_col]\n",
        "    item_id = self.data.iloc[idx][self.item_col]\n",
        "    genres = self.data.iloc[idx][self.genre_col]\n",
        "    rating = self.data.iloc[idx][self.score_col]\n",
        "\n",
        "    user_idx = self.user_mapping[user_id]\n",
        "    genre_idxs = [self.genre_mapping[genre] for genre in genres.split('|')] # Is now a list\n",
        "    item_idx = self.item_mapping[item_id]\n",
        "\n",
        "    # First thought here was to write [user_idx, item_idx, genre_idxs, rating], but using [] + creates a flat list, concatenating the elements of genre_idxs\n",
        "    # rather than the list itself. Easier to parse inside the model\n",
        "    return torch.tensor([user_idx, item_idx, rating] + genre_idxs, dtype=torch.float32)\n",
        "\n",
        "  # Helper function called in initialization\n",
        "  def _get_unique_genres(self):\n",
        "    unique_genres = set()\n",
        "    for genres in self.data[self.genre_col].unique():\n",
        "      unique_genres.update(genres.split('|'))\n",
        "    return list(unique_genres)"
      ],
      "metadata": {
        "id": "3TvgJzbwBVci"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Needed to handle variable length of samples' genre index lists. Pad tensors per batch\n",
        "def collate_fn_with_padding(batch):\n",
        "\n",
        "  # Extract individual components from the batch\n",
        "  batch_size = len(batch)\n",
        "\n",
        "  user_idxs = torch.zeros(batch_size, dtype=torch.long)\n",
        "  item_idxs = torch.zeros(batch_size, dtype=torch.long)\n",
        "  ratings = torch.zeros(batch_size, dtype=torch.float32)\n",
        "  max_num_genres = max(len(item) - 3 for item in batch)  # Calculate max length of genre indices\n",
        "\n",
        "  genre_idxs_padded = []\n",
        "\n",
        "  for i, item in enumerate(batch):\n",
        "\n",
        "    user_idxs[i] = item[0]\n",
        "    item_idxs[i] = item[1]\n",
        "    ratings[i] = item[2]\n",
        "    genre_idxs = torch.tensor(item[3:], dtype=torch.long)\n",
        "    padded_genre_idxs = torch.cat([genre_idxs, torch.zeros(max_num_genres - len(genre_idxs), dtype=torch.long)])\n",
        "    genre_idxs_padded.append(padded_genre_idxs)\n",
        "\n",
        "  genre_idxs_padded = torch.stack(genre_idxs_padded, dim=0)\n",
        "\n",
        "  # Concatenate all tensors into a single tensor\n",
        "  batch_tensor = torch.cat([user_idxs.unsqueeze(1),\n",
        "                            item_idxs.unsqueeze(1),\n",
        "                            ratings.unsqueeze(1),\n",
        "                            genre_idxs_padded], dim=1)\n",
        "\n",
        "  return batch_tensor"
      ],
      "metadata": {
        "id": "nIJz-e4FmOiy"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_data_loaders(trn_df, val_df, user_col, item_col, score_col, genre_col=None, batch_size=64):\n",
        "  '''\n",
        "  user_col: str name of column in dataframe containing user ids\n",
        "  item_col: str name of column in dataframe containing item ids\n",
        "  genre_col: (optional) str name of column in dataframe containing genres\n",
        "  score_col: str name of column in dataframe containing ratings\n",
        "  '''\n",
        "  trn_ds = None\n",
        "  val_ds = None\n",
        "  trn_dl = None\n",
        "  val_dl = None\n",
        "\n",
        "  if genre_col is None:\n",
        "    trn_ds = collabSimpleDataset(trn_df, user_col, item_col, score_col)\n",
        "    val_ds = collabSimpleDataset(val_df, user_col, item_col, score_col)\n",
        "\n",
        "    trn_dl = DataLoader(trn_ds, batch_size=batch_size, shuffle=True)\n",
        "    val_dl = DataLoader(val_ds, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "  else:\n",
        "    trn_ds = collabExtendedDataset(trn_df, user_col, item_col, genre_col, score_col)\n",
        "    val_ds = collabExtendedDataset(val_df, user_col, item_col, genre_col, score_col)\n",
        "\n",
        "    trn_dl = DataLoader(trn_ds, batch_size=batch_size, shuffle=True, collate_fn=collate_fn_with_padding) # See custom collate method above\n",
        "    val_dl = DataLoader(val_ds, batch_size=batch_size, shuffle=True, collate_fn=collate_fn_with_padding)\n",
        "\n",
        "  return trn_dl, val_dl, trn_ds, val_ds"
      ],
      "metadata": {
        "id": "bF9nebNckrcp"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# The Models\n",
        "First, the PMF based models and then the neural net"
      ],
      "metadata": {
        "id": "v75F-Y1XBCvK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def sigmoid_range(x, low, high):\n",
        "  '''\n",
        "  Sigmoid function with range `(low, high)`\n",
        "  https://github.com/fastai/fastai/blob/master/fastai/layers.py#L100\n",
        "  '''\n",
        "  return torch.sigmoid(x) * (high - low) + low"
      ],
      "metadata": {
        "id": "ih88GkNSBFpo"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Simple PMF, user and item only\n",
        "class DotProductBias(nn.Module):\n",
        "  def __init__(self, n_users, n_items, n_factors, y_range=(0,5.5)):\n",
        "    super().__init__()\n",
        "    self.user_factors = nn.Embedding(n_users, n_factors)\n",
        "    self.user_bias = nn.Embedding(n_users, 1)\n",
        "    self.item_factors = nn.Embedding(n_items, n_factors)\n",
        "    self.item_bias = nn.Embedding(n_items, 1)\n",
        "    self.y_range = y_range\n",
        "\n",
        "    # Initialize embeddings and biases\n",
        "    nn.init.normal_(self.user_factors.weight, std=0.01)\n",
        "    nn.init.normal_(self.item_factors.weight, std=0.01)\n",
        "    nn.init.normal_(self.user_bias.weight, std=0.01)\n",
        "    nn.init.normal_(self.item_bias.weight, std=0.01)\n",
        "\n",
        "  def forward(self, x):\n",
        "\n",
        "    user_idx = x[:, 0].long()\n",
        "    item_idx = x[:, 1].long()\n",
        "    #ratings = x[:, 2]\n",
        "\n",
        "    users = self.user_factors(user_idx)\n",
        "    items = self.item_factors(item_idx)\n",
        "    users_bias = self.user_bias(user_idx).squeeze()\n",
        "    items_bias = self.item_bias(item_idx).squeeze()\n",
        "\n",
        "    dot_product = torch.sum(users * items, dim=1)\n",
        "    bias = users_bias + items_bias\n",
        "\n",
        "    prediction = dot_product + bias\n",
        "    return sigmoid_range(prediction, *self.y_range)"
      ],
      "metadata": {
        "id": "5mYMU1NWl9Fm"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Incorporate another feature\n",
        "class DPBWithItemFeatures(nn.Module):\n",
        "  '''\n",
        "    Similar dot-product model but with room for an extra categorical/feature (currently genres), which is taken into account for the item\n",
        "    Could easily be modified to handle more features, for either users or items\n",
        "    '''\n",
        "  def __init__(self, n_users, n_items, n_genres, n_factors, y_range=(0,5.5)):\n",
        "    super().__init__()\n",
        "    self.user_factors = nn.Embedding(n_users, n_factors)\n",
        "    self.user_bias = nn.Embedding(n_users, 1)\n",
        "    self.item_factors = nn.Embedding(n_items, n_factors)\n",
        "    self.item_bias = nn.Embedding(n_items, 1)\n",
        "    self.genre_factors = nn.Embedding(n_genres, n_factors)\n",
        "    self.genre_bias = nn.Embedding(n_genres, 1)\n",
        "    self.y_range = y_range\n",
        "\n",
        "    # Initialize embeddings and biases\n",
        "    nn.init.normal_(self.user_factors.weight, std=0.01)\n",
        "    nn.init.normal_(self.item_factors.weight, std=0.01)\n",
        "    nn.init.normal_(self.genre_factors.weight, std=0.01)\n",
        "    nn.init.normal_(self.user_bias.weight, std=0.01)\n",
        "    nn.init.normal_(self.item_bias.weight, std=0.01)\n",
        "    nn.init.normal_(self.genre_bias.weight, std=0.01)\n",
        "\n",
        "  def forward(self, x):\n",
        "\n",
        "    user_idx = x[:, 0].long()\n",
        "    item_idx = x[:, 1].long()\n",
        "    # ratings = x[:, 2].long()\n",
        "    genre_idxs = x[:, 3:].long() # Assuming genres now take up the 4th column and onward\n",
        "\n",
        "    users = self.user_factors(user_idx)\n",
        "    items = self.item_factors(item_idx)\n",
        "    users_bias = self.user_bias(user_idx).squeeze()\n",
        "    items_bias = self.item_bias(item_idx).squeeze()\n",
        "\n",
        "    # Embedding lookup for genres\n",
        "    genres_embedded = self.genre_factors(genre_idxs)\n",
        "\n",
        "    # Currently summing biases of all the genres of the sample. Could also average\n",
        "    genre_bias = self.genre_bias(genre_idxs).squeeze().sum(dim=1)\n",
        "\n",
        "    # Multiple ways to use of the genre embeddings, especially if they are of different size than the item embeddings\n",
        "    #item_with_genre = items.unsqueeze(1) * genres_embedded\n",
        "    items_with_genre = torch.cat([items.unsqueeze(1) * genres_embedded, items.unsqueeze(1)], dim=1)\n",
        "\n",
        "    # Sum the effect of each genre's factors on the item factors, reduce dimensionality from (n_samples, n_genres, n_item_factors) to (n_samples, n_item_factors)\n",
        "    # This is assuming item embedding and genre embedding sizes are equal\n",
        "    items_with_genre = items_with_genre.sum(dim=1) # or mean\n",
        "\n",
        "    dot_product = torch.sum(users * items_with_genre, dim=1)\n",
        "    bias = users_bias + items_bias + genre_bias\n",
        "\n",
        "    prediction = dot_product + bias\n",
        "    return sigmoid_range(prediction, *self.y_range)"
      ],
      "metadata": {
        "id": "CZmWRq1npcWI"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Single hidden layer neural net, again only user + item\n",
        "class nnSimpleCollab(nn.Module):\n",
        "  def __init__(self, user_size, item_size, hidden_dim=128, y_range=(0,5.5)):\n",
        "    super().__init__()\n",
        "    self.user_embedding = nn.Embedding(*user_size)\n",
        "    self.item_embedding = nn.Embedding(*item_size)\n",
        "\n",
        "    # Realistically, incorporating dropout and/or other regularization techniques should be experimented with\n",
        "    self.fc_layers = nn.Sequential(\n",
        "      nn.Linear(user_size[1] + item_size[1], hidden_dim),\n",
        "      nn.ReLU(),\n",
        "      nn.Linear(hidden_dim, 1)  # Output is a single rating prediction\n",
        "      )\n",
        "\n",
        "    self.y_range = y_range\n",
        "\n",
        "  def forward(self, x):\n",
        "\n",
        "    user_embedded = self.user_embedding(x[:, 0].long())\n",
        "    item_embedded = self.item_embedding(x[:, 1].long())\n",
        "\n",
        "    # Concatenate user and item embeddings\n",
        "    embedded = torch.cat([user_embedded, item_embedded], dim=1)\n",
        "\n",
        "    # Pass through layers\n",
        "    output = self.fc_layers(embedded)\n",
        "\n",
        "    # Scale to y_range\n",
        "    output = sigmoid_range(output, *self.y_range)\n",
        "\n",
        "    return output.squeeze()"
      ],
      "metadata": {
        "id": "bD7bZvHqBHPK"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Adds handling of additional (genre) feature\n",
        "class nnExtendedCollab(nn.Module):\n",
        "  def __init__(self, user_size, item_size, genre_size, hidden_dim=128, y_range=(0,5.5)):\n",
        "    super().__init__()\n",
        "    self.user_embedding = nn.Embedding(*user_size)\n",
        "    self.item_embedding = nn.Embedding(*item_size)\n",
        "    self.genre_embedding = nn.Embedding(*genre_size)\n",
        "\n",
        "    '''\n",
        "    We need to know what size to make our first linear layer, which is passed a concatenation of relevent embeddings.\n",
        "    Couple of ways to handle the possible variable number of genres per item:\n",
        "      1. Sum or average genres found, and then concatenating the user and item embeddings with the summed/averaged genre embedding (which has the size of a single genre embedding)\n",
        "        In this case, we only need the first layer to be (user_size[1] + item_size[1] + genre_size[1])\n",
        "      2. Concatenate each relevent genre embedding to the user and item embeddings, padding unused space with 0's\n",
        "        In this case, we need the first layer to be (user_size[1] + item_size[1] + max_num_genres * genre_size[1])\n",
        "        Thus we will need to find the sample with the most genres before creating the model\n",
        "\n",
        "    We will take the first approach for starters\n",
        "    '''\n",
        "\n",
        "    self.fc_layers = nn.Sequential(\n",
        "      nn.Linear(user_size[1] + item_size[1] + genre_size[1], hidden_dim),\n",
        "      nn.ReLU(),\n",
        "      nn.Linear(hidden_dim, 1)  # Output is a single rating prediction\n",
        "      )\n",
        "\n",
        "    self.y_range = y_range\n",
        "\n",
        "  def forward(self, x):\n",
        "\n",
        "    user_idx = x[:, 0].long()\n",
        "    item_idx = x[:, 1].long()\n",
        "    # ratings = x[:, 2].long()\n",
        "    genre_idxs = x[:, 3:].long() # Assuming genres now take up the 4th column and onward\n",
        "\n",
        "    user_embedded = self.user_embedding(user_idx)\n",
        "    item_embedded = self.item_embedding(item_idx)\n",
        "    genres_embedded = self.genre_embedding(genre_idxs)\n",
        "\n",
        "    # Sum/avg genre embeddings\n",
        "    genre_embedded = torch.sum(genres_embedded, dim=1)\n",
        "    #genre_embedded = torch.mean(genres_embedded, dim=1)\n",
        "\n",
        "    # Concatenate embeddings\n",
        "    embedded = torch.cat([user_embedded, item_embedded, genre_embedded], dim=1)\n",
        "\n",
        "    # Pass through layers\n",
        "    output = self.fc_layers(embedded)\n",
        "\n",
        "    # Scale to y_range\n",
        "    output = sigmoid_range(output, *self.y_range)\n",
        "\n",
        "    return output.squeeze()"
      ],
      "metadata": {
        "id": "UHsqYP6fDvFn"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training + Inference"
      ],
      "metadata": {
        "id": "7lw2CF7Ups95"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Simple training loop. Assumes rating is 3rd column in dataset\n",
        "def train_pytorch_model(model, train_loader, optimizer, criterion, epochs=5):\n",
        "  for epoch in range(epochs):\n",
        "\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    for batch in train_loader:\n",
        "\n",
        "      targets = batch[:, 2]\n",
        "\n",
        "      optimizer.zero_grad()\n",
        "\n",
        "      outputs = model(batch)\n",
        "      loss = criterion(outputs, targets)\n",
        "\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "\n",
        "      running_loss += loss.item()\n",
        "\n",
        "    print(f\"Epoch {epoch+1}, Loss: {running_loss / len(train_loader)}\")"
      ],
      "metadata": {
        "id": "i4ohpwCr3iUH"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Some simple preprocessing"
      ],
      "metadata": {
        "id": "ISXE2q9s3joN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eOf52lhgqE5X",
        "outputId": "df35cd34-0736-420c-878c-582d120cd2b5"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ratings_df = pd.read_csv('/content/drive/My Drive/Colab Notebooks/ML+DL/movielens_ratings.csv')\n",
        "# Grab movie names from other csv\n",
        "names_df = pd.read_csv('/content/drive/My Drive/Colab Notebooks/ML+DL/movielens_movies.csv')\n",
        "# Merge into ratings df\n",
        "ratings_df = ratings_df.merge(names_df, on='movieId')\n",
        "\n",
        "ratings_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "ywWL2nsQ2GQx",
        "outputId": "38056f24-641f-4c89-8e37-9fc694c9db85"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        userId  movieId  rating   timestamp                             title  \\\n",
              "0            1        1     4.0   964982703                  Toy Story (1995)   \n",
              "1            5        1     4.0   847434962                  Toy Story (1995)   \n",
              "2            7        1     4.5  1106635946                  Toy Story (1995)   \n",
              "3           15        1     2.5  1510577970                  Toy Story (1995)   \n",
              "4           17        1     4.5  1305696483                  Toy Story (1995)   \n",
              "...        ...      ...     ...         ...                               ...   \n",
              "100831     610   160341     2.5  1479545749                  Bloodmoon (1997)   \n",
              "100832     610   160527     4.5  1479544998  Sympathy for the Underdog (1971)   \n",
              "100833     610   160836     3.0  1493844794                     Hazard (2005)   \n",
              "100834     610   163937     3.5  1493848789                Blair Witch (2016)   \n",
              "100835     610   163981     3.5  1493850155                         31 (2016)   \n",
              "\n",
              "                                             genres  \n",
              "0       Adventure|Animation|Children|Comedy|Fantasy  \n",
              "1       Adventure|Animation|Children|Comedy|Fantasy  \n",
              "2       Adventure|Animation|Children|Comedy|Fantasy  \n",
              "3       Adventure|Animation|Children|Comedy|Fantasy  \n",
              "4       Adventure|Animation|Children|Comedy|Fantasy  \n",
              "...                                             ...  \n",
              "100831                              Action|Thriller  \n",
              "100832                           Action|Crime|Drama  \n",
              "100833                        Action|Drama|Thriller  \n",
              "100834                              Horror|Thriller  \n",
              "100835                                       Horror  \n",
              "\n",
              "[100836 rows x 6 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-3d97a068-4156-492c-bfd4-69781976f7d4\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>userId</th>\n",
              "      <th>movieId</th>\n",
              "      <th>rating</th>\n",
              "      <th>timestamp</th>\n",
              "      <th>title</th>\n",
              "      <th>genres</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>4.0</td>\n",
              "      <td>964982703</td>\n",
              "      <td>Toy Story (1995)</td>\n",
              "      <td>Adventure|Animation|Children|Comedy|Fantasy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>4.0</td>\n",
              "      <td>847434962</td>\n",
              "      <td>Toy Story (1995)</td>\n",
              "      <td>Adventure|Animation|Children|Comedy|Fantasy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>7</td>\n",
              "      <td>1</td>\n",
              "      <td>4.5</td>\n",
              "      <td>1106635946</td>\n",
              "      <td>Toy Story (1995)</td>\n",
              "      <td>Adventure|Animation|Children|Comedy|Fantasy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>15</td>\n",
              "      <td>1</td>\n",
              "      <td>2.5</td>\n",
              "      <td>1510577970</td>\n",
              "      <td>Toy Story (1995)</td>\n",
              "      <td>Adventure|Animation|Children|Comedy|Fantasy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>17</td>\n",
              "      <td>1</td>\n",
              "      <td>4.5</td>\n",
              "      <td>1305696483</td>\n",
              "      <td>Toy Story (1995)</td>\n",
              "      <td>Adventure|Animation|Children|Comedy|Fantasy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>100831</th>\n",
              "      <td>610</td>\n",
              "      <td>160341</td>\n",
              "      <td>2.5</td>\n",
              "      <td>1479545749</td>\n",
              "      <td>Bloodmoon (1997)</td>\n",
              "      <td>Action|Thriller</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>100832</th>\n",
              "      <td>610</td>\n",
              "      <td>160527</td>\n",
              "      <td>4.5</td>\n",
              "      <td>1479544998</td>\n",
              "      <td>Sympathy for the Underdog (1971)</td>\n",
              "      <td>Action|Crime|Drama</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>100833</th>\n",
              "      <td>610</td>\n",
              "      <td>160836</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1493844794</td>\n",
              "      <td>Hazard (2005)</td>\n",
              "      <td>Action|Drama|Thriller</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>100834</th>\n",
              "      <td>610</td>\n",
              "      <td>163937</td>\n",
              "      <td>3.5</td>\n",
              "      <td>1493848789</td>\n",
              "      <td>Blair Witch (2016)</td>\n",
              "      <td>Horror|Thriller</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>100835</th>\n",
              "      <td>610</td>\n",
              "      <td>163981</td>\n",
              "      <td>3.5</td>\n",
              "      <td>1493850155</td>\n",
              "      <td>31 (2016)</td>\n",
              "      <td>Horror</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>100836 rows Ã— 6 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3d97a068-4156-492c-bfd4-69781976f7d4')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-3d97a068-4156-492c-bfd4-69781976f7d4 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-3d97a068-4156-492c-bfd4-69781976f7d4');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-881f5d43-0174-4e98-8e4f-e8f4f43cbf71\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-881f5d43-0174-4e98-8e4f-e8f4f43cbf71')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-881f5d43-0174-4e98-8e4f-e8f4f43cbf71 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_942276f8-c06c-44c6-9634-2c40972a35fa\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('ratings_df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_942276f8-c06c-44c6-9634-2c40972a35fa button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('ratings_df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "ratings_df"
            }
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#np.random.seed(42)\n",
        "trn_df,val_df = train_test_split(ratings_df, test_size=0.25)\n",
        "\n",
        "n_users = len(ratings_df.userId.unique())\n",
        "n_movies = len(ratings_df.movieId.unique())\n",
        "n_factors = 50\n",
        "\n",
        "print(n_users)\n",
        "print(n_movies)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lR8NL66t2gBq",
        "outputId": "da22bd7c-2ef4-4167-f480-67aadb2a994f"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "610\n",
            "9724\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ready to build dataloaders and train."
      ],
      "metadata": {
        "id": "V3sGh71k2_qX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# First, the standard PMF model\n",
        "trn_dl, val_dl, trn_ds, val_ds = create_data_loaders(trn_df, val_df, 'userId', 'title', 'rating') # No genre column, no neural net\n",
        "test_model = DotProductBias(n_users, n_movies, n_factors)"
      ],
      "metadata": {
        "id": "IxZSiwuR5TQL"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#optimizer = torch.optim.Adam(test_model.parameters(), lr=0.005, weight_decay=0.1)\n",
        "optimizer = torch.optim.Adam(test_model.parameters(), lr=0.005)\n",
        "criterion = nn.MSELoss()"
      ],
      "metadata": {
        "id": "Yol7pK0b687s"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_pytorch_model(test_model, trn_dl, optimizer, criterion, epochs=10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IE1AOoNS7Eqx",
        "outputId": "80fa4368-4c61-453a-b43d-0c16585e8997"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Loss: 0.9080956054570913\n",
            "Epoch 2, Loss: 0.4273509998914554\n",
            "Epoch 3, Loss: 0.23368170141997271\n",
            "Epoch 4, Loss: 0.1821519449454072\n",
            "Epoch 5, Loss: 0.1768910806002048\n",
            "Epoch 6, Loss: 0.17468626905617174\n",
            "Epoch 7, Loss: 0.16799746335258742\n",
            "Epoch 8, Loss: 0.16370294591673537\n",
            "Epoch 9, Loss: 0.15908487692992196\n",
            "Epoch 10, Loss: 0.15605366658639988\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now some inference. Couple of interesting things to examine are item-item similarities and item bias values. In our case, user-user similarities and biases are not of much use since the users are only identified by IDs."
      ],
      "metadata": {
        "id": "EebrQs5r-Qx1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract item bias embeddings from the model\n",
        "item_bias_embeddings = test_model.item_bias.weight.squeeze().detach().numpy()\n",
        "\n",
        "# Map the item bias embeddings back to their original item IDs, using the mapping we created in the dataset\n",
        "item_biases = [(item_id, item_bias_embeddings[item_idx]) for item_id, item_idx in trn_ds.item_mapping.items()]\n",
        "\n",
        "# Sort items based on bias values\n",
        "sorted_item_biases = sorted(item_biases, key=lambda x: x[1], reverse=True)\n",
        "\n",
        "# Output the items with the highest bias\n",
        "num_top_items = 10\n",
        "top_items_with_bias = sorted_item_biases[:num_top_items]\n",
        "print(f\"Top {num_top_items} items ranked by bias:\")\n",
        "for item_id, bias_value in top_items_with_bias:\n",
        "  print(f\"Item ID: {item_id}, Bias Value: {bias_value}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pU82kd_j-plj",
        "outputId": "30517fad-5639-48cf-c99e-edcc1f1816b3"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top 10 items ranked by bias bias:\n",
            "Item ID: Shawshank Redemption, The (1994), Bias Value: 1.0387192964553833\n",
            "Item ID: Lawrence of Arabia (1962), Bias Value: 0.9313034415245056\n",
            "Item ID: Star Wars: Episode IV - A New Hope (1977), Bias Value: 0.8656998872756958\n",
            "Item ID: Fight Club (1999), Bias Value: 0.8644293546676636\n",
            "Item ID: Star Wars: Episode V - The Empire Strikes Back (1980), Bias Value: 0.8625494837760925\n",
            "Item ID: 12 Angry Men (1957), Bias Value: 0.8552147746086121\n",
            "Item ID: Philadelphia Story, The (1940), Bias Value: 0.8292230367660522\n",
            "Item ID: Hustler, The (1961), Bias Value: 0.8070851564407349\n",
            "Item ID: Godfather, The (1972), Bias Value: 0.8061210513114929\n",
            "Item ID: Usual Suspects, The (1995), Bias Value: 0.8020727634429932\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_item_item_similarity(model, item_embeddings):\n",
        "  model.eval()\n",
        "\n",
        "  # Get item embeddings\n",
        "  #item_embeddings = model.item_factors.weight  # shape: (num_items, embedding_size)\n",
        "\n",
        "  # Normalize item embeddings to unit length\n",
        "  item_norms = torch.norm(item_embeddings, dim=1, keepdim=True)  # shape: (num_items, 1)\n",
        "  item_embeddings_normalized = item_embeddings / item_norms\n",
        "\n",
        "  # Calculate cosine similarities between all pairs of item embeddings\n",
        "  cosine_similarities = torch.matmul(item_embeddings_normalized, item_embeddings_normalized.T)  # shape: (num_items, num_items)\n",
        "\n",
        "  return cosine_similarities"
      ],
      "metadata": {
        "id": "ZmUUi_WjAacz"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cosine_sims = calculate_item_item_similarity(test_model, test_model.item_factors.weight)"
      ],
      "metadata": {
        "id": "JBWG3SRhGBb_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Choose movie to inspect cosine similarities\n",
        "base_item_id = 'Lawrence of Arabia (1962)'\n",
        "item_idx = trn_ds.item_mapping[base_item_id]\n",
        "\n",
        "similar_items = torch.argsort(cosine_sims[item_idx], descending=True)\n",
        "\n",
        "# Print top 5 similar items\n",
        "top_k = 5\n",
        "for i in range(1, top_k + 1):  # Skip the first item (itself)\n",
        "    similar_item_idx = similar_items[i].item()\n",
        "    similar_item_id = next(key for key, val in trn_ds.item_mapping.items() if val == similar_item_idx)\n",
        "\n",
        "    similarity_score = cosine_sims[item_idx, similar_item_idx].item()\n",
        "    print(f\"Item: {base_item_id} is similar to Item: {similar_item_id} with similarity score: {similarity_score:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tej-xrz2F23g",
        "outputId": "82a46823-7abe-47cf-ea1a-2695a357e008"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Item: Lawrence of Arabia (1962) is similar to Item: Hunt for Red October, The (1990) with similarity score: 0.5442\n",
            "Item: Lawrence of Arabia (1962) is similar to Item: Man for All Seasons, A (1966) with similarity score: 0.5387\n",
            "Item: Lawrence of Arabia (1962) is similar to Item: Monster (2003) with similarity score: 0.5188\n",
            "Item: Lawrence of Arabia (1962) is similar to Item: Perfect Plan, A (Plan parfait, Un) (2012) with similarity score: 0.4984\n",
            "Item: Lawrence of Arabia (1962) is similar to Item: Pickup on South Street (1953) with similarity score: 0.4911\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Lets just test the raw predictions, on the validation set this time\n",
        "def test_model_preds(model, val_dl, criterion):\n",
        "    model.eval()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        total_loss = 0\n",
        "        num_batches = 0\n",
        "\n",
        "        for i, batch in enumerate(val_dl):\n",
        "            # Extract targets from the batch\n",
        "            targets = batch[:, 2]  # Ratings\n",
        "\n",
        "            # Forward pass to get predictions\n",
        "            predictions = model(batch)\n",
        "\n",
        "            # Ensure targets and predictions are the same shape\n",
        "            if predictions.shape != targets.shape:\n",
        "                raise ValueError(f\"Shape mismatch: predictions {predictions.shape}, targets {targets.shape}\")\n",
        "\n",
        "            # Compute loss\n",
        "            loss = criterion(predictions, targets)\n",
        "            total_loss += loss.item()\n",
        "            num_batches += 1\n",
        "\n",
        "            # Print predictions and targets\n",
        "            for pred, actual in zip(predictions, targets):\n",
        "                print(f\"Predicted: {pred.item():.2f}, Actual: {actual.item()}\")\n",
        "\n",
        "        # Print average loss\n",
        "        average_loss = total_loss / num_batches if num_batches > 0 else float('nan')\n",
        "        print(f\"Validation loss: {average_loss:.4f}\")"
      ],
      "metadata": {
        "id": "8AlwVlFBGWRN"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_model_preds(test_model, val_dl, criterion)"
      ],
      "metadata": {
        "id": "FZ77w3OCHdfL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lets compare with the standard neural net based model. Then we will compare the genre-inclusive models"
      ],
      "metadata": {
        "id": "Q4wq0olzJNmH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Method to calculate an embedding size for a feature, based on the number of categories / unique values it holds.\n",
        "# We will use it to determine our embedding sizes for users and items based on the number of each present in our dataset\n",
        "def get_emb_size(n_cat):\n",
        "  '''\n",
        "  Quickly calculate number of factors for embedding layer of the given column in the dataframe\n",
        "  https://github.com/fastai/fastai/blob/master/fastai/tabular/model.py#L12\n",
        "  '''\n",
        "\n",
        "  n_factors = min(600, round(1.6 * n_cat**0.56))\n",
        "  return int(n_factors)"
      ],
      "metadata": {
        "id": "XlLBI-2DJaeV"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_model = nnSimpleCollab((n_users, get_emb_size(n_users)), (n_movies, get_emb_size(n_movies)))\n",
        "\n",
        "# Update optimizer to new model, criterion can stay the same\n",
        "optimizer = torch.optim.Adam(test_model.parameters(), lr=0.001)\n",
        "# criterion = nn.MSELoss()"
      ],
      "metadata": {
        "id": "D81W5nUoK5Ys"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_pytorch_model(test_model, trn_dl, optimizer, criterion, epochs=10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GNYslQBVLew1",
        "outputId": "7ca16d3f-4dbb-4f1c-a5aa-948cb31a6aaf"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Loss: 0.9046981757768318\n",
            "Epoch 2, Loss: 0.7558842561823866\n",
            "Epoch 3, Loss: 0.6947595283969001\n",
            "Epoch 4, Loss: 0.6480425290902052\n",
            "Epoch 5, Loss: 0.6055868424084384\n",
            "Epoch 6, Loss: 0.5627825580247364\n",
            "Epoch 7, Loss: 0.5188155913388265\n",
            "Epoch 8, Loss: 0.4719425866950789\n",
            "Epoch 9, Loss: 0.42646533763902844\n",
            "Epoch 10, Loss: 0.3820772226616211\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Off the bat, the NN model takes longer to train and at least by training loss, did not reach the same accuracy as the PMF model. Lets check the validation accuracy just for the heck. Was about 1.7 on my last run of the PMF model."
      ],
      "metadata": {
        "id": "wexAtamFNjdx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_model_preds(test_model, val_dl, criterion)"
      ],
      "metadata": {
        "id": "e0MZIUchOWKO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Similar results (~1.75). Obiously, there is likely room for improvement in terms of regularization and hyperparameter tuning. Lets move on to the models incorporating genre information"
      ],
      "metadata": {
        "id": "j6tpwAkvOfeH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the number of unique genres\n",
        "unique_genres = set()\n",
        "for genres in ratings_df.genres.unique():\n",
        "  unique_genres.update(genres.split('|'))\n",
        "n_genres = len(list(unique_genres))\n",
        "\n",
        "n_genres"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RgJCwZlOOyyQ",
        "outputId": "48f8b2bf-f955-4208-e4d7-3a62d3879e8b"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "20"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Recreate dataloaders with genre info\n",
        "trn_dl, val_dl, trn_ds, val_ds = create_data_loaders(trn_df, val_df, 'userId', 'title', 'rating', 'genres')\n",
        "\n",
        "test_model = DPBWithItemFeatures(n_users, n_movies, n_genres, n_factors)\n",
        "\n",
        "optimizer = torch.optim.Adam(test_model.parameters(), lr=0.005)\n",
        "#criterion = nn.MSELoss()"
      ],
      "metadata": {
        "id": "aJwhhDl5PYPW"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_pytorch_model(test_model, trn_dl, optimizer, criterion, epochs=10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bMNS4FsoQjs_",
        "outputId": "2e610ccd-e456-4180-ace7-00602f9bc736"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-5-e6de06c078b0>:19: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  genre_idxs = torch.tensor(item[3:], dtype=torch.long)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Loss: 0.8236763685336573\n",
            "Epoch 2, Loss: 0.5048020575101\n",
            "Epoch 3, Loss: 0.26478905312704354\n",
            "Epoch 4, Loss: 0.18226403080544698\n",
            "Epoch 5, Loss: 0.15894147946598566\n",
            "Epoch 6, Loss: 0.14689810131558306\n",
            "Epoch 7, Loss: 0.1365100285526863\n",
            "Epoch 8, Loss: 0.1297222082353435\n",
            "Epoch 9, Loss: 0.12939203933335197\n",
            "Epoch 10, Loss: 0.12286290533008612\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can now inspect the genre biases and genre-genre similarities. Slight modification to code used above (for item biases and item-item similarities)"
      ],
      "metadata": {
        "id": "L1pmW49-Rmgt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "genre_bias_embeddings = test_model.genre_bias.weight.squeeze().detach().numpy()\n",
        "\n",
        "# Map back to their original genre ids/names\n",
        "genre_biases = [(genre_id, genre_bias_embeddings[genre_idx]) for genre_id, genre_idx in trn_ds.genre_mapping.items()]\n",
        "\n",
        "sorted_genre_biases = sorted(genre_biases, key=lambda x: x[1], reverse=True)\n",
        "\n",
        "num_top_items = 10\n",
        "top_genres_with_bias = sorted_genre_biases[:num_top_items]\n",
        "print(f\"Top {num_top_items} genres ranked by bias:\")\n",
        "for genre_id, bias_value in top_genres_with_bias:\n",
        "  print(f\"Genre: {genre_id}, Bias Value: {bias_value}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZOKAvzV5RxpB",
        "outputId": "97b9e255-d185-458f-98dc-31c50e9bed32"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top 10 genres ranked by bias:\n",
            "Genre: Documentary, Bias Value: 0.6882173418998718\n",
            "Genre: Film-Noir, Bias Value: 0.36215248703956604\n",
            "Genre: Drama, Bias Value: 0.359806627035141\n",
            "Genre: Animation, Bias Value: 0.2901704013347626\n",
            "Genre: War, Bias Value: 0.2563265264034271\n",
            "Genre: Western, Bias Value: 0.2541514039039612\n",
            "Genre: Crime, Bias Value: 0.18676279485225677\n",
            "Genre: Mystery, Bias Value: 0.14704154431819916\n",
            "Genre: Musical, Bias Value: 0.14622989296913147\n",
            "Genre: Comedy, Bias Value: 0.1361905336380005\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cosine_sims = calculate_item_item_similarity(test_model, test_model.genre_factors.weight)"
      ],
      "metadata": {
        "id": "KOfrW6jJSzPw"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Choose genre to inspect cosine similarities\n",
        "base_genre_id = 'Thriller'\n",
        "genre_idx = trn_ds.genre_mapping[base_genre_id]\n",
        "\n",
        "similar_genres = torch.argsort(cosine_sims[genre_idx], descending=True)\n",
        "\n",
        "# Print top 5 similar genres\n",
        "top_k = 5\n",
        "for i in range(1, top_k + 1):  # Skip the first genre (itself)\n",
        "    similar_genre_idx = similar_genres[i].item()\n",
        "    similar_genre_id = next(key for key, val in trn_ds.genre_mapping.items() if val == similar_genre_idx)\n",
        "\n",
        "    similarity_score = cosine_sims[genre_idx, similar_genre_idx].item()\n",
        "    print(f\"Genre: {base_genre_id} is similar to genre: {similar_genre_id} with similarity score: {similarity_score:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D7WKZk7_TZVw",
        "outputId": "2732f11d-12c7-4fe2-ef1d-f2ebcd28774d"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Genre: Thriller is similar to genre: Drama with similarity score: 0.6790\n",
            "Genre: Thriller is similar to genre: (no genres listed) with similarity score: 0.6747\n",
            "Genre: Thriller is similar to genre: Horror with similarity score: 0.6723\n",
            "Genre: Thriller is similar to genre: Children with similarity score: 0.5754\n",
            "Genre: Thriller is similar to genre: Documentary with similarity score: 0.5740\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's see the predictions and validation loss"
      ],
      "metadata": {
        "id": "sz8EECuCT6Sn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_model_preds(test_model, val_dl, criterion)"
      ],
      "metadata": {
        "id": "JvQOvPXcUAIk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Oof, not great (>2.0 my last run). Perhaps there is room for better handling of the genre embeddings (averaging rather than summing per sample, etc). Lets take a look with the NN version."
      ],
      "metadata": {
        "id": "rm78b3avUL1Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_model = nnExtendedCollab((n_users, get_emb_size(n_users)), (n_movies, get_emb_size(n_movies)), (n_genres, get_emb_size(n_genres)))\n",
        "\n",
        "optimizer = torch.optim.Adam(test_model.parameters(), lr=0.001)\n",
        "#criterion = nn.MSELoss()"
      ],
      "metadata": {
        "id": "MItZzGRNU0a6"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_pytorch_model(test_model, trn_dl, optimizer, criterion, epochs=10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1E8iRP16VCkG",
        "outputId": "69701fa2-89d1-47fc-a9b9-ecfe04105b8a"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-5-e6de06c078b0>:19: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  genre_idxs = torch.tensor(item[3:], dtype=torch.long)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Loss: 0.9001253139095258\n",
            "Epoch 2, Loss: 0.7494193808429334\n",
            "Epoch 3, Loss: 0.684297267379091\n",
            "Epoch 4, Loss: 0.6326422305831247\n",
            "Epoch 5, Loss: 0.583021673832448\n",
            "Epoch 6, Loss: 0.5327189792004333\n",
            "Epoch 7, Loss: 0.48103412732406314\n",
            "Epoch 8, Loss: 0.43207636150309275\n",
            "Epoch 9, Loss: 0.3880645381113398\n",
            "Epoch 10, Loss: 0.34925424819418216\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_model_preds(test_model, val_dl, criterion)"
      ],
      "metadata": {
        "id": "DiWp50pFX6jl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Off the bat, still not great (~2.5 val loss). Again there is room for changes to the handling of genre data, and for hyperparameter tuning. Monitoring validation loss during training, and stopping when the best tradeoff of training and validation loss is reached may be beneficial. Rounding predictions to the nearest .5 at the last step may be of help. More testing to be done, as always :)"
      ],
      "metadata": {
        "id": "cqt4DnRKYG7q"
      }
    }
  ]
}